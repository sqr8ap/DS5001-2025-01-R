{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b610773e-ebe3-497e-9e73-ff95b61ed511",
   "metadata": {},
   "source": [
    "# M06 Homework\n",
    "\n",
    "- Name: Sam Remmey\n",
    "- Net ID: sqr8ap\n",
    "- URL of this file in GitHub: https://github.com/sqr8ap/DS5001-2025-01-R/blob/m06/lessons/M06_ClusteringSimilarity/M06_HW.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0853828c-0e45-45a1-9e0e-0a837b81c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../../../env.ini\")\n",
    "data_hone = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cf26598-c2db-4ef3-a4a3-8eaa87a7dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prefix = 'austen-melville'\n",
    "OHCO = ['book_id', 'chap_id']\n",
    "OHCO_token = ['book_id', 'chap_id', 'para_num', 'sent_num', 'token_num']\n",
    "bag = 'CHAPS'\n",
    "colors = \"YlGnBu\"\n",
    "tf_agg = 'sum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c3ff269-06aa-491b-87da-14c51c7b6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly_express as px\n",
    "import seaborn as sns; sns.set()\n",
    "from numpy.linalg import norm\n",
    "from scipy.spatial.distance import pdist\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23977f35-f923-4274-aacb-be1a3bfe30f8",
   "metadata": {},
   "source": [
    "## Pre-Question Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c25abd-72d8-497e-be49-aa4f1a813969",
   "metadata": {},
   "source": [
    "### Import & Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1526e72-1195-4ce8-b0d1-69d528871f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB = pd.read_csv(f\"{output_dir}/{data_prefix}-LIB.csv\").set_index('book_id')\n",
    "TOKEN = pd.read_csv(f'{output_dir}/{data_prefix}-CORPUS.csv').set_index(OHCO_token).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e639bb93-3aab-48e6-a9a8-134d2399aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>chap_regex</th>\n",
       "      <th>book_len</th>\n",
       "      <th>n_chaps</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>/Users/Samantha/Desktop/MSDS/DS5001/data/guten...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>PERSUASION</td>\n",
       "      <td>^Chapter\\s+\\d+$</td>\n",
       "      <td>83624</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>/Users/Samantha/Desktop/MSDS/DS5001/data/guten...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>NORTHANGER ABBEY</td>\n",
       "      <td>^CHAPTER\\s+\\d+$</td>\n",
       "      <td>77601</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>/Users/Samantha/Desktop/MSDS/DS5001/data/guten...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>MANSFIELD PARK</td>\n",
       "      <td>^CHAPTER\\s+[IVXLCM]+$</td>\n",
       "      <td>160378</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>/Users/Samantha/Desktop/MSDS/DS5001/data/guten...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>EMMA</td>\n",
       "      <td>^\\s*CHAPTER\\s+[IVXLCM]+\\s*$</td>\n",
       "      <td>160926</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>/Users/Samantha/Desktop/MSDS/DS5001/data/guten...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>SENSE AND SENSIBILITY</td>\n",
       "      <td>^CHAPTER\\s+\\d+$</td>\n",
       "      <td>119873</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path        author  \\\n",
       "book_id                                                                    \n",
       "105      /Users/Samantha/Desktop/MSDS/DS5001/data/guten...  AUSTEN, JANE   \n",
       "121      /Users/Samantha/Desktop/MSDS/DS5001/data/guten...  AUSTEN, JANE   \n",
       "141      /Users/Samantha/Desktop/MSDS/DS5001/data/guten...  AUSTEN, JANE   \n",
       "158      /Users/Samantha/Desktop/MSDS/DS5001/data/guten...  AUSTEN, JANE   \n",
       "161      /Users/Samantha/Desktop/MSDS/DS5001/data/guten...  AUSTEN, JANE   \n",
       "\n",
       "                         title                   chap_regex  book_len  n_chaps  \n",
       "book_id                                                                         \n",
       "105                 PERSUASION              ^Chapter\\s+\\d+$     83624       24  \n",
       "121           NORTHANGER ABBEY              ^CHAPTER\\s+\\d+$     77601       31  \n",
       "141             MANSFIELD PARK        ^CHAPTER\\s+[IVXLCM]+$    160378       48  \n",
       "158                       EMMA  ^\\s*CHAPTER\\s+[IVXLCM]+\\s*$    160926       55  \n",
       "161      SENSE AND SENSIBILITY              ^CHAPTER\\s+\\d+$    119873       50  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6fa8903-fe4f-42c2-abae-48eb8cc322de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add feature to LIB for publication year\n",
    "title_to_year = {\n",
    "    'EMMA': '1815 EMMA',\n",
    "    'LADY SUSAN': '1794 LADY SUSAN',\n",
    "    'LOVE AND FREINDSHIP SIC': '1790 LOVE AND FREINDSHIP',\n",
    "    'MANSFIELD PARK': '1814 MANSFIELD PARK',\n",
    "    'NORTHANGER ABBEY': '1803 NORTHANGER ABBEY',\n",
    "    'PERSUASION': '1818 PERSUASION',\n",
    "    'PRIDE AND PREJUDICE': '1813 PRIDE AND PREJUDICE',\n",
    "    'SENSE AND SENSIBILITY': '1811 SENSE AND SENSIBILITY'\n",
    "}\n",
    "LIB['year'] = LIB['title'].map(title_to_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "376cca8c-8bef-454c-ab62-d5e565b6a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in functions from last homework, modify TFIDF to include DFIDF\n",
    "def gen_bow(TOKENS, OHCO_LEVEL='CHAPS'):\n",
    "    '''\n",
    "    This function takes a tokens table and a choice of bag and returns a BOW representation in the form of a document-term count matrix. \n",
    "\n",
    "    Parameters\n",
    "    TOKENS: tokens table; a dataframe\n",
    "    OCHO_LEVEL: choice of bag; a string (either 'BOOKS', 'CHAPS', 'PARAS' or 'SENTS'); defaults to 'CHAPS'\n",
    "\n",
    "    Returns\n",
    "    DTCM: document-term count matrix\n",
    "    '''\n",
    "    \n",
    "    bags = dict(\n",
    "        SENTS = OHCO[:4],\n",
    "        PARAS = OHCO[:3],\n",
    "        CHAPS = OHCO[:2],\n",
    "        BOOKS = OHCO[:1])\n",
    "    \n",
    "    BOW = TOKENS.groupby(bags[OHCO_LEVEL]+['term_str']).term_str.count().to_frame('n')\n",
    "    DTCM = BOW.n.unstack(fill_value=0)\n",
    "\n",
    "    return DTCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31eee6ed-b675-4d9a-bfae-67860866fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tfidf(DTCM, TF_METHOD='sum'):\n",
    "    '''\n",
    "    This function takes a BOW table (DTCM) and type of tf metric and returns the TFIDF values for the BOW. \n",
    "\n",
    "    Parameters\n",
    "    DTCM: BOW table; a dataframe\n",
    "    TF_METHOD: a string; either 'sum', 'max', 'log', 'raw', 'double_norm' or 'binary'; defaults to 'sum'\n",
    "\n",
    "    Returns\n",
    "    TFIDF: a dataframe\n",
    "    '''\n",
    "\n",
    "    tf_norm_k = 0.5\n",
    "    idf_method = 'standard'\n",
    "    gradient_cmap = 'YlGnBu'\n",
    "    tf = {\n",
    "        'sum': (DTCM.T / DTCM.T.sum()).T,\n",
    "        'max': (DTCM.T / DTCM.T.max()).T,\n",
    "        'log': (np.log2(1 + DTCM.T)).T,\n",
    "        'raw':  DTCM,\n",
    "        'double_norm': (DTCM.T / DTCM.T.max()).T,\n",
    "        'binary': DTCM.T.astype('bool').astype('int').T}\n",
    "\n",
    "    TF = tf[TF_METHOD]\n",
    "\n",
    "    DF = DTCM.astype('bool').sum() \n",
    "\n",
    "    N = DTCM.shape[0]   \n",
    "    \n",
    "    IDF = np.log2(N / DF)\n",
    "\n",
    "    TFIDF = TF * IDF\n",
    "    DFIDF = DF * IDF\n",
    "    \n",
    "    return TFIDF, DFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a186cd3f-4410-4c91-9678-ad76fedfca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to Austen's works only using chapters as bags and max as the tf method\n",
    "LIB = LIB.loc[LIB['author'] == 'AUSTEN, JANE']\n",
    "TOKEN = TOKEN.loc[TOKEN.index.get_level_values('book_id').isin([158, 946, 1212, 141, 121, 105, 1342, 161])]\n",
    "\n",
    "my_dtcm = gen_bow(TOKEN) # default bag level is chapter\n",
    "idfs = gen_tfidf(my_dtcm, TF_METHOD = 'max')\n",
    "TFIDF, DFIDF = idfs[0], idfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9bc95e91-bdbb-4bb4-93e1-f577de78e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce number of features in TFIDF matrix\n",
    "\n",
    "## First generate VOCAB table\n",
    "VOCAB = TOKEN.term_str.value_counts().to_frame('n').sort_index()\n",
    "VOCAB.index.name = 'term_str'\n",
    "VOCAB['n_chars'] = VOCAB.index.str.len()\n",
    "VOCAB['p'] = VOCAB.n / VOCAB.n.sum()\n",
    "VOCAB['i'] = -np.log2(VOCAB.p)\n",
    "VOCAB['max_pos'] = TOKEN[['term_str','pos']].value_counts().unstack(fill_value=0).idxmax(1)\n",
    "VOCAB['max_pos_group'] = TOKEN[['term_str','pos_group']].value_counts().unstack(fill_value=0).idxmax(1)\n",
    "\n",
    "## Filter and reduce TFIDF matrix\n",
    "pos = {\"NN\", \"NNS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"JJ\", \"JJR\", \"JJS\", \"RB\", \"RBR\", \"RBS\"}\n",
    "pos_match = VOCAB[VOCAB['max_pos'].isin(pos)].index\n",
    "filtered_dfidf = DFIDF[DFIDF.index.isin(pos_match)]\n",
    "top_terms = filtered_dfidf.nlargest(1000).index\n",
    "TFIDF = TFIDF[top_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9c8b3244-98f8-463a-b6b4-466885b42c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>forward</th>\n",
       "      <th>greatest</th>\n",
       "      <th>respect</th>\n",
       "      <th>stay</th>\n",
       "      <th>thinking</th>\n",
       "      <th>assure</th>\n",
       "      <th>fortune</th>\n",
       "      <th>marriage</th>\n",
       "      <th>believed</th>\n",
       "      <th>entered</th>\n",
       "      <th>...</th>\n",
       "      <th>number</th>\n",
       "      <th>picture</th>\n",
       "      <th>powers</th>\n",
       "      <th>scene</th>\n",
       "      <th>sensations</th>\n",
       "      <th>stairs</th>\n",
       "      <th>tired</th>\n",
       "      <th>truly</th>\n",
       "      <th>unable</th>\n",
       "      <th>till</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">105</th>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023435</td>\n",
       "      <td>0.035152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023321</td>\n",
       "      <td>0.046643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015457</td>\n",
       "      <td>0.030415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011911</td>\n",
       "      <td>0.011911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011911</td>\n",
       "      <td>0.024016</td>\n",
       "      <td>0.048032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041774</td>\n",
       "      <td>0.010443</td>\n",
       "      <td>0.042115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020955</td>\n",
       "      <td>0.016893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1342</th>\n",
       "      <th>57</th>\n",
       "      <td>0.023626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019742</td>\n",
       "      <td>0.019742</td>\n",
       "      <td>0.019742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>0.039807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039614</td>\n",
       "      <td>0.079229</td>\n",
       "      <td>0.015967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.018243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028259</td>\n",
       "      <td>0.028259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028490</td>\n",
       "      <td>0.142448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056703</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "term_str          forward  greatest   respect      stay  thinking    assure  \\\n",
       "book_id chap_id                                                               \n",
       "105     1        0.000000  0.000000  0.023245  0.000000  0.023245  0.000000   \n",
       "        2        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "        3        0.000000  0.011911  0.011911  0.000000  0.011911  0.024016   \n",
       "        4        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "        5        0.010443  0.000000  0.000000  0.041774  0.010443  0.042115   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "1342    57       0.023626  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "        58       0.000000  0.000000  0.014858  0.000000  0.000000  0.029958   \n",
       "        59       0.000000  0.019742  0.019742  0.019742  0.000000  0.000000   \n",
       "        60       0.018243  0.000000  0.018243  0.000000  0.018243  0.000000   \n",
       "        61       0.000000  0.000000  0.028259  0.028259  0.000000  0.000000   \n",
       "\n",
       "term_str          fortune  marriage  believed   entered  ...  number  picture  \\\n",
       "book_id chap_id                                          ...                    \n",
       "105     1        0.023435  0.035152  0.000000  0.000000  ...  0.0000   0.0000   \n",
       "        2        0.000000  0.015457  0.030415  0.000000  ...  0.0000   0.0000   \n",
       "        3        0.048032  0.000000  0.000000  0.000000  ...  0.0239   0.0239   \n",
       "        4        0.057354  0.000000  0.037619  0.000000  ...  0.0000   0.0000   \n",
       "        5        0.000000  0.021057  0.000000  0.000000  ...  0.0000   0.0000   \n",
       "...                   ...       ...       ...       ...  ...     ...      ...   \n",
       "1342    57       0.000000  0.142915  0.000000  0.000000  ...  0.0000   0.0000   \n",
       "        58       0.000000  0.000000  0.044212  0.000000  ...  0.0000   0.0000   \n",
       "        59       0.019904  0.039807  0.000000  0.039165  ...  0.0000   0.0000   \n",
       "        60       0.000000  0.018392  0.000000  0.000000  ...  0.0000   0.0000   \n",
       "        61       0.028490  0.142448  0.000000  0.000000  ...  0.0000   0.0000   \n",
       "\n",
       "term_str         powers     scene  sensations    stairs  tired     truly  \\\n",
       "book_id chap_id                                                            \n",
       "105     1           0.0  0.023321    0.046643  0.000000    0.0  0.000000   \n",
       "        2           0.0  0.000000    0.000000  0.000000    0.0  0.000000   \n",
       "        3           0.0  0.000000    0.000000  0.000000    0.0  0.000000   \n",
       "        4           0.0  0.000000    0.000000  0.000000    0.0  0.000000   \n",
       "        5           0.0  0.020955    0.000000  0.000000    0.0  0.000000   \n",
       "...                 ...       ...         ...       ...    ...       ...   \n",
       "1342    57          0.0  0.000000    0.000000  0.000000    0.0  0.047407   \n",
       "        58          0.0  0.000000    0.000000  0.000000    0.0  0.000000   \n",
       "        59          0.0  0.000000    0.000000  0.039614    0.0  0.039614   \n",
       "        60          0.0  0.000000    0.000000  0.000000    0.0  0.000000   \n",
       "        61          0.0  0.000000    0.000000  0.000000    0.0  0.000000   \n",
       "\n",
       "term_str           unable      till  \n",
       "book_id chap_id                      \n",
       "105     1        0.000000  0.000000  \n",
       "        2        0.000000  0.000000  \n",
       "        3        0.000000  0.004817  \n",
       "        4        0.000000  0.000000  \n",
       "        5        0.020955  0.016893  \n",
       "...                   ...       ...  \n",
       "1342    57       0.000000  0.009554  \n",
       "        58       0.000000  0.012017  \n",
       "        59       0.079229  0.015967  \n",
       "        60       0.000000  0.014755  \n",
       "        61       0.056703  0.000000  \n",
       "\n",
       "[334 rows x 1000 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
