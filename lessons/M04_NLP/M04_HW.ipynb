{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1ef22e6-ac6a-4dce-a30d-b382df66836b",
   "metadata": {},
   "source": [
    "# M04 Homework\n",
    "- Name: Sam Remmey\n",
    "- Net ID: sqr8ap\n",
    "- URL of this file in GitHub: https://github.com/sqr8ap/DS5001-2025-01-R/blob/m04/lessons/M04_NLP/M04_HW.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8408fa4d-ab84-4550-afc8-46e8ff520235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "import plotly_express as px\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90fec9b6-d313-4ce0-b989-b0831358fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"../../../env.ini\")\n",
    "data_home = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']\n",
    "local_lib = config['DEFAULT']['local_lib']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04cf614c-9bcc-4706-ae29-4a017d1d1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(local_lib)\n",
    "from textparser import TextParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a6aa751-d201-4528-99fc-68db60d0d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_files = f'{data_home}/gutenberg/eliot-set'\n",
    "data_prefix = 'eliot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb1637f-2cb8-49d7-96ca-cc5187305cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCO = ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f5bcc0-b8fe-4272-9c5b-c9c1e6c9b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_pats = [\n",
    "    r\"\\*\\*\\*\\s*START OF\",\n",
    "    r\"\\*\\*\\*\\s*END OF\"\n",
    "]\n",
    "\n",
    "# All are 'chap'and 'm'\n",
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "ohco_pat_list = [\n",
    "    (507,   rf\"^\\s*Chapter\\s+{roman}\\s*$\"),\n",
    "    (145,   rf\"^\\s*CHAPTER\\s+{roman}\\s*\\.$\"),\n",
    "    #(6688,   rf\"\\s^Chapter\\s+{roman}+\\.\\s*$\"),\n",
    "    (6688,   rf\"^\\s*Chapter\\s+{roman}\\.\\s*$\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20fa31cc-d983-4e0a-b851-ffa38510821e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/Samantha/Desktop/MSDS/DS5001/data/gutenberg/eliot-set/ELIOT_GEORGE_ADAM_BEDE-pg507.txt',\n",
       " '/Users/Samantha/Desktop/MSDS/DS5001/data/gutenberg/eliot-set/ELIOT_GEORGE_MIDDLEMARCH-pg145.txt',\n",
       " '/Users/Samantha/Desktop/MSDS/DS5001/data/gutenberg/eliot-set/ELIOT_GEORGE_THE_MILL_ON_THE_FLOSS-pg6688.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file_list = sorted(glob(f\"{source_files}/*.*\"))\n",
    "source_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ced31206-8da2-4639-b438-3247005c742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data = []\n",
    "for source_file_path in source_file_list:\n",
    "    book_id = int(source_file_path.split('-')[-1].split('.')[0].replace('pg',''))\n",
    "    book_title = source_file_path.split('/')[-1].split('-')[0].replace('_', ' ')\n",
    "    book_data.append((book_id, source_file_path, book_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd82807-ae1e-44df-922b-acc8d9a4e971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(507,\n",
       "  '/Users/Samantha/Desktop/MSDS/DS5001/data/gutenberg/eliot-set/ELIOT_GEORGE_ADAM_BEDE-pg507.txt',\n",
       "  'ELIOT GEORGE ADAM BEDE'),\n",
       " (145,\n",
       "  '/Users/Samantha/Desktop/MSDS/DS5001/data/gutenberg/eliot-set/ELIOT_GEORGE_MIDDLEMARCH-pg145.txt',\n",
       "  'ELIOT GEORGE MIDDLEMARCH'),\n",
       " (6688,\n",
       "  '/Users/Samantha/Desktop/MSDS/DS5001/data/gutenberg/eliot-set/ELIOT_GEORGE_THE_MILL_ON_THE_FLOSS-pg6688.txt',\n",
       "  'ELIOT GEORGE THE MILL ON THE FLOSS')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1190247e-007e-4e61-93fa-e1ae672be48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB = pd.DataFrame(book_data, columns=['book_id','source_file_path','raw_title'])\\\n",
    "    .set_index('book_id').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37e860a4-ee6b-46b8-b68f-bde20f99786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['chap_regex'] = LIB.index.map(pd.Series({x[0]:x[1] for x in ohco_pat_list}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ff756dc-25f3-4e0e-9096-6b20393a4306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize corpus\n",
    "\n",
    "def tokenize_collection(LIB):\n",
    "\n",
    "    clip_pats = [\n",
    "        r\"\\*\\*\\*\\s*START OF\",\n",
    "        r\"\\*\\*\\*\\s*END OF\"\n",
    "    ]\n",
    "\n",
    "    books = []\n",
    "    for book_id in LIB.index:\n",
    "\n",
    "        # Announce\n",
    "        print(\"Tokenizing\", book_id, LIB.loc[book_id].raw_title)\n",
    "\n",
    "        # Define vars\n",
    "        chap_regex = LIB.loc[book_id].chap_regex\n",
    "        ohco_pats = [('chap', chap_regex, 'm')]\n",
    "        src_file_path = LIB.loc[book_id].source_file_path\n",
    "\n",
    "        # Create object\n",
    "        text = TextParser(src_file_path, ohco_pats=ohco_pats, clip_pats=clip_pats, use_nltk=True)\n",
    "        # text = TextImporter(src_file_path, ohco_pats=ohco_pats, clip_pats=clip_pats) \n",
    "\n",
    "        # Define parameters\n",
    "        text.verbose = True\n",
    "        text.strip_hyphens = True\n",
    "        text.strip_whitespace = True\n",
    "\n",
    "        # Parse\n",
    "        #text.import_source().parse_tokens();\n",
    "        try:\n",
    "            text.import_source().parse_tokens()\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing book {book_id}: {e}\")  # Debugging print\n",
    "            continue\n",
    "\n",
    "        ### Debug: Print the TOKENS structure after parsing\n",
    "        print(f\"Tokens for {book_id}:\", text.TOKENS.head())\n",
    "\n",
    "        # Name things\n",
    "        text.TOKENS['book_id'] = book_id\n",
    "        text.TOKENS = text.TOKENS.reset_index().set_index(['book_id'] + text.OHCO)\n",
    "\n",
    "        # Add to list\n",
    "        books.append(text.TOKENS)\n",
    "        \n",
    "    # Combine into a single dataframe\n",
    "    CORPUS = pd.concat(books).sort_index()\n",
    "\n",
    "    # Clean up\n",
    "    del(books)\n",
    "    del(text)\n",
    "        \n",
    "    print(\"Done\")\n",
    "        \n",
    "    return CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e07b0d1-2b24-48e7-b099-141daff046b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^\\\\s*CHAPTER\\\\s+[IVXLCM]+\\\\s*\\\\.$'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.loc[145].chap_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea4701ae-2ec2-4262-a28c-2a55b539420e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Samantha/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Samantha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/Samantha/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c1d3ee5-2d63-4209-b7dc-4fb2a107308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing 145 ELIOT GEORGE MIDDLEMARCH\n",
      "Importing  /Users/Samantha/Desktop/MSDS/DS5001/data/gutenberg/eliot-set/ELIOT_GEORGE_MIDDLEMARCH-pg145.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*CHAPTER\\s+[IVXLCM]+\\s*\\.$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokens for 145:                                        pos_tuple  pos token_str term_str\n",
      "chap_id para_num sent_num token_num                                     \n",
      "1       0        0        0          (Since, IN)   IN     Since    since\n",
      "                          1             (I, PRP)  PRP         I        i\n",
      "                          2            (can, MD)   MD       can      can\n",
      "                          3             (do, VB)   VB        do       do\n",
      "                          4             (no, DT)   DT        no       no\n",
      "Tokenizing 507 ELIOT GEORGE ADAM BEDE\n",
      "Importing  /Users/Samantha/Desktop/MSDS/DS5001/data/gutenberg/eliot-set/ELIOT_GEORGE_ADAM_BEDE-pg507.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*Chapter\\s+[IVXLCM]+\\s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokens for 507:                                            pos_tuple  pos token_str  term_str\n",
      "chap_id para_num sent_num token_num                                          \n",
      "1       0        0        0                (The, DT)   DT       The       the\n",
      "                          1          (Workshop, NNP)  NNP  Workshop  workshop\n",
      "        1        0        0               (With, IN)   IN      With      with\n",
      "                          1                  (a, DT)   DT         a         a\n",
      "                          2             (single, JJ)   JJ    single    single\n",
      "Tokenizing 6688 ELIOT GEORGE THE MILL ON THE FLOSS\n",
      "Importing  /Users/Samantha/Desktop/MSDS/DS5001/data/gutenberg/eliot-set/ELIOT_GEORGE_THE_MILL_ON_THE_FLOSS-pg6688.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*Chapter\\s+[IVXLCM]+\\.\\s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokens for 6688:                                            pos_tuple  pos token_str  term_str\n",
      "chap_id para_num sent_num token_num                                          \n",
      "1       0        0        0            (Outside, JJ)   JJ   Outside   outside\n",
      "                          1          (Dorlcote, NNP)  NNP  Dorlcote  dorlcote\n",
      "                          2              (Mill, NNP)  NNP      Mill      mill\n",
      "        1        0        0                  (A, DT)   DT         A         a\n",
      "                          1               (wide, JJ)   JJ      wide      wide\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "CORPUS = tokenize_collection(LIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ca532c1-c35c-4790-be47-2de0f59705b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['book_len'] = CORPUS.groupby('book_id').term_str.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa7ee912-5c63-4115-ac7f-f31da9b17f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['n_chaps'] = CORPUS.reset_index()[['book_id','chap_id']]\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby('book_id').chap_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff07c1f-7eeb-4de5-b5cf-38efe7b19ffa",
   "metadata": {},
   "source": [
    "### FINAL LIB TABLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af7814cb-8c33-46d6-bae1-edb82603d60a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>book_id</th>\n",
       "      <th>145</th>\n",
       "      <th>507</th>\n",
       "      <th>6688</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source_file_path</th>\n",
       "      <td>/Users/Samantha/Desktop/MSDS/DS5001/data/guten...</td>\n",
       "      <td>/Users/Samantha/Desktop/MSDS/DS5001/data/guten...</td>\n",
       "      <td>/Users/Samantha/Desktop/MSDS/DS5001/data/guten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_title</th>\n",
       "      <td>ELIOT GEORGE MIDDLEMARCH</td>\n",
       "      <td>ELIOT GEORGE ADAM BEDE</td>\n",
       "      <td>ELIOT GEORGE THE MILL ON THE FLOSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_regex</th>\n",
       "      <td>^\\s*CHAPTER\\s+[IVXLCM]+\\s*\\.$</td>\n",
       "      <td>^\\s*Chapter\\s+[IVXLCM]+\\s*$</td>\n",
       "      <td>^\\s*Chapter\\s+[IVXLCM]+\\.\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_len</th>\n",
       "      <td>317305</td>\n",
       "      <td>215404</td>\n",
       "      <td>207461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_chaps</th>\n",
       "      <td>86</td>\n",
       "      <td>55</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "book_id                                                        145   \\\n",
       "source_file_path  /Users/Samantha/Desktop/MSDS/DS5001/data/guten...   \n",
       "raw_title                                  ELIOT GEORGE MIDDLEMARCH   \n",
       "chap_regex                            ^\\s*CHAPTER\\s+[IVXLCM]+\\s*\\.$   \n",
       "book_len                                                     317305   \n",
       "n_chaps                                                          86   \n",
       "\n",
       "book_id                                                        507   \\\n",
       "source_file_path  /Users/Samantha/Desktop/MSDS/DS5001/data/guten...   \n",
       "raw_title                                    ELIOT GEORGE ADAM BEDE   \n",
       "chap_regex                              ^\\s*Chapter\\s+[IVXLCM]+\\s*$   \n",
       "book_len                                                     215404   \n",
       "n_chaps                                                          55   \n",
       "\n",
       "book_id                                                        6688  \n",
       "source_file_path  /Users/Samantha/Desktop/MSDS/DS5001/data/guten...  \n",
       "raw_title                        ELIOT GEORGE THE MILL ON THE FLOSS  \n",
       "chap_regex                            ^\\s*Chapter\\s+[IVXLCM]+\\.\\s*$  \n",
       "book_len                                                     207461  \n",
       "n_chaps                                                          58  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b966ffb-e464-46a7-ae89-4523a2bbe872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>24</th>\n",
       "      <td>(little, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">145</th>\n",
       "      <th>17</th>\n",
       "      <th>23</th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "      <td>(generally, RB)</td>\n",
       "      <td>RB</td>\n",
       "      <td>generally</td>\n",
       "      <td>generally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <th>44</th>\n",
       "      <th>1</th>\n",
       "      <th>45</th>\n",
       "      <td>(about;, NNS)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>about;</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <th>18</th>\n",
       "      <th>0</th>\n",
       "      <th>43</th>\n",
       "      <td>(to, TO)</td>\n",
       "      <td>TO</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <th>16</th>\n",
       "      <th>2</th>\n",
       "      <th>47</th>\n",
       "      <td>(with, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pos_tuple  pos  token_str  \\\n",
       "book_id chap_id para_num sent_num token_num                                    \n",
       "507     2       1        0        24            (little, JJ)   JJ     little   \n",
       "145     17      23       0        5          (generally, RB)   RB  generally   \n",
       "        46      44       1        45           (about;, NNS)  NNS     about;   \n",
       "        64      18       0        43                (to, TO)   TO         to   \n",
       "        48      16       2        47              (with, IN)   IN       with   \n",
       "\n",
       "                                              term_str  \n",
       "book_id chap_id para_num sent_num token_num             \n",
       "507     2       1        0        24            little  \n",
       "145     17      23       0        5          generally  \n",
       "        46      44       1        45             about  \n",
       "        64      18       0        43                to  \n",
       "        48      16       2        47              with  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a8836ed-89e4-4b3e-b6c5-43619f65d292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token_str\n",
       "&      10\n",
       "…       3\n",
       ");      2\n",
       "),      2\n",
       "):      1\n",
       ";”      1\n",
       "(&)     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS[CORPUS.term_str == ''].token_str.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23dc98d3-b4d5-4903-b866-f131c664e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = CORPUS[CORPUS.term_str != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0cf06f6-4ea8-4f1e-bae9-1229af085408",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS['pos_group'] = CORPUS.pos.str[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e25117-42b4-496b-bd2a-f7d39350c78c",
   "metadata": {},
   "source": [
    "### FINAL CORPUS TABLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1c96165-dc69-45b7-84c1-914831cc951d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>145</th>\n",
       "      <th>6688</th>\n",
       "      <th>507</th>\n",
       "      <th colspan=\"2\" halign=\"left\">6688</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_id</th>\n",
       "      <th>62</th>\n",
       "      <th>5</th>\n",
       "      <th>15</th>\n",
       "      <th>52</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>para_num</th>\n",
       "      <th>4</th>\n",
       "      <th>73</th>\n",
       "      <th>11</th>\n",
       "      <th>61</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_num</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>13</th>\n",
       "      <th>12</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_num</th>\n",
       "      <th>0</th>\n",
       "      <th>19</th>\n",
       "      <th>39</th>\n",
       "      <th>44</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pos_tuple</th>\n",
       "      <td>(If, IN)</td>\n",
       "      <td>(although, IN)</td>\n",
       "      <td>(for, IN)</td>\n",
       "      <td>(approached,, NN)</td>\n",
       "      <td>(Tulliver,, NNP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_str</th>\n",
       "      <td>If</td>\n",
       "      <td>although</td>\n",
       "      <td>for</td>\n",
       "      <td>approached,</td>\n",
       "      <td>Tulliver,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <td>if</td>\n",
       "      <td>although</td>\n",
       "      <td>for</td>\n",
       "      <td>approached</td>\n",
       "      <td>tulliver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_group</th>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "book_id        145             6688       507                6688  \\\n",
       "chap_id          62              5          15                 52   \n",
       "para_num         4               73         11                 61   \n",
       "sent_num         0               1          13                 12   \n",
       "token_num        0               19         39                 44   \n",
       "pos_tuple  (If, IN)  (although, IN)  (for, IN)  (approached,, NN)   \n",
       "pos              IN              IN         IN                 NN   \n",
       "token_str        If        although        for        approached,   \n",
       "term_str         if        although        for         approached   \n",
       "pos_group        IN              IN         IN                 NN   \n",
       "\n",
       "book_id                      \n",
       "chap_id                  13  \n",
       "para_num                 9   \n",
       "sent_num                 0   \n",
       "token_num                33  \n",
       "pos_tuple  (Tulliver,, NNP)  \n",
       "pos                     NNP  \n",
       "token_str         Tulliver,  \n",
       "term_str           tulliver  \n",
       "pos_group                NN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1351a729-491d-426b-8a41-60a5d8dc2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = CORPUS.term_str.value_counts().to_frame('n').sort_index()\n",
    "VOCAB.index.name = 'term_str'\n",
    "VOCAB['n_chars'] = VOCAB.index.str.len()\n",
    "VOCAB['p'] = VOCAB.n / VOCAB.n.sum()\n",
    "VOCAB['i'] = -np.log2(VOCAB.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fec3878-c636-4bb5-a09f-c0dc0921d826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cataract</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.497458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tackled</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.497458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protective</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.497458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starchy</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.497458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zest</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>16.912496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            n  n_chars         p          i\n",
       "term_str                                   \n",
       "cataract    1        8  0.000001  19.497458\n",
       "tackled     1        7  0.000001  19.497458\n",
       "protective  1       10  0.000001  19.497458\n",
       "starchy     1        7  0.000001  19.497458\n",
       "zest        6        4  0.000008  16.912496"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e44e1726-9e96-426e-bb49-cd9b0ef7f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11f6acb9-c6d9-435a-bfde-518abb7f0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['stop'] = VOCAB.index.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c6868e4-eb7a-4b79-855d-b66397bf8fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>each</th>\n",
       "      <td>294</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>11.297786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>684</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>10.079606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>after</th>\n",
       "      <td>844</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>9.776359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herself</th>\n",
       "      <td>520</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>10.475090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itself</th>\n",
       "      <td>180</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>12.005605</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>having</th>\n",
       "      <td>387</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>10.901268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>2605</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>8.150390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yourself</th>\n",
       "      <td>158</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>12.193677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>11491</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>6.009241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>during</th>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>13.347711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              n  n_chars         p          i  stop\n",
       "term_str                                           \n",
       "each        294        4  0.000397  11.297786     1\n",
       "where       684        5  0.000924  10.079606     1\n",
       "after       844        5  0.001140   9.776359     1\n",
       "herself     520        7  0.000703  10.475090     1\n",
       "itself      180        6  0.000243  12.005605     1\n",
       "having      387        6  0.000523  10.901268     1\n",
       "all        2605        3  0.003520   8.150390     1\n",
       "yourself    158        8  0.000213  12.193677     1\n",
       "in        11491        2  0.015525   6.009241     1\n",
       "during       71        6  0.000096  13.347711     1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB[VOCAB.stop == 1].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34e43ee7-4222-45ab-9eaa-cfa60c7cb2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['stem_porter'] = VOCAB.apply(lambda x: stemmer1.stem(x.name), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "220326c9-6a38-48c8-a67d-8a1ffd9a1126",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['max_pos'] = CORPUS[['term_str','pos']].value_counts().unstack(fill_value=0).idxmax(1)\n",
    "VOCAB['max_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().unstack(fill_value=0).idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "155b35a6-c992-4892-b0c4-5dfde72fddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['n_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().unstack().count(1)\n",
    "VOCAB['cat_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().to_frame('n').reset_index()\\\n",
    "    .groupby('term_str').pos_group.apply(lambda x: set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c23e9b23-26dc-4306-aae9-ff11dc8995b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['n_pos'] = CORPUS[['term_str','pos']].value_counts().unstack().count(1)\n",
    "VOCAB['cat_pos'] = CORPUS[['term_str','pos']].value_counts().to_frame('n').reset_index()\\\n",
    "    .groupby('term_str').pos.apply(lambda x: set(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd216b4-c92f-4c2a-929c-c2ea9e629d8c",
   "metadata": {},
   "source": [
    "### FINAL VOCAB TABLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba14222c-ff3e-4124-8def-c03011d557c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>term_str</th>\n",
       "      <th>close</th>\n",
       "      <th>champagne</th>\n",
       "      <th>shying</th>\n",
       "      <th>fellowmen</th>\n",
       "      <th>beliefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_chars</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>11.958299</td>\n",
       "      <td>19.497458</td>\n",
       "      <td>19.497458</td>\n",
       "      <td>19.497458</td>\n",
       "      <td>17.17553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem_porter</th>\n",
       "      <td>close</td>\n",
       "      <td>champagn</td>\n",
       "      <td>shi</td>\n",
       "      <td>fellowmen</td>\n",
       "      <td>belief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_pos</th>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_pos_group</th>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_pos_group</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_pos_group</th>\n",
       "      <td>{JJ, RB, VB, NN}</td>\n",
       "      <td>{NN}</td>\n",
       "      <td>{JJ}</td>\n",
       "      <td>{NN}</td>\n",
       "      <td>{NN}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_pos</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_pos</th>\n",
       "      <td>{RB, VBP, NNP, VBD, JJ, VB, NN}</td>\n",
       "      <td>{NN}</td>\n",
       "      <td>{JJ}</td>\n",
       "      <td>{NN}</td>\n",
       "      <td>{NNS, NN}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "term_str                                 close  champagne     shying  \\\n",
       "n                                          186          1          1   \n",
       "n_chars                                      5          9          6   \n",
       "p                                     0.000251   0.000001   0.000001   \n",
       "i                                    11.958299  19.497458  19.497458   \n",
       "stop                                         0          0          0   \n",
       "stem_porter                              close   champagn        shi   \n",
       "max_pos                                     JJ         NN         JJ   \n",
       "max_pos_group                               JJ         NN         JJ   \n",
       "n_pos_group                                  4          1          1   \n",
       "cat_pos_group                 {JJ, RB, VB, NN}       {NN}       {JJ}   \n",
       "n_pos                                        7          1          1   \n",
       "cat_pos        {RB, VBP, NNP, VBD, JJ, VB, NN}       {NN}       {JJ}   \n",
       "\n",
       "term_str       fellowmen    beliefs  \n",
       "n                      1          5  \n",
       "n_chars                9          7  \n",
       "p               0.000001   0.000007  \n",
       "i              19.497458   17.17553  \n",
       "stop                   0          0  \n",
       "stem_porter    fellowmen     belief  \n",
       "max_pos               NN        NNS  \n",
       "max_pos_group         NN         NN  \n",
       "n_pos_group            1          1  \n",
       "cat_pos_group       {NN}       {NN}  \n",
       "n_pos                  1          2  \n",
       "cat_pos             {NN}  {NNS, NN}  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(5).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a04e40-bf62-438b-907f-d52019c61b71",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc782860-ba5f-4133-b4e5-1be1a3ba3706",
   "metadata": {},
   "source": [
    "#### 1. What regular expression did you use to chunk _Middlemarch_ into chapters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42a40432-a0a7-4ac5-a521-942107b86957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^\\\\s*CHAPTER\\\\s+[IVXLCM]+\\\\s*\\\\.$'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.loc[LIB['raw_title'] == 'ELIOT GEORGE MIDDLEMARCH', 'chap_regex'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a75753b-d522-474d-a0aa-2c88d7d3bf5c",
   "metadata": {},
   "source": [
    "#### 2. What is the title of the book that has the most tokens? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90030e25-0993-4bd4-9ddb-13774e78a300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MIDDLEMARCH'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.loc[LIB['book_len'] == max(LIB['book_len']), 'raw_title'].values[0].split()[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f4471d-abf7-458b-9df4-72f9161e9cc0",
   "metadata": {},
   "source": [
    "#### 3. How many chapter level chunks are there in this novel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c483776-9889-4ece-a705-c799d61964b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.loc[LIB['raw_title'] == 'ELIOT GEORGE MIDDLEMARCH', 'n_chaps'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d3ac9-f777-4fe9-b3fb-68a78793d6db",
   "metadata": {},
   "source": [
    "#### 4. Among the three stemming algorithms -- Porter, Lancaster, and Snowball --  which is the most aggressive, in terms of the number of words associated with each stem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45cf851d-4c76-40c4-9a82-83a1d530b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer2 = SnowballStemmer(\"english\")\n",
    "VOCAB['stem_snowball'] = VOCAB.apply(lambda x: stemmer2.stem(x.name), 1)\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer3 = LancasterStemmer()\n",
    "VOCAB['stem_lancaster'] = VOCAB.apply(lambda x: stemmer3.stem(x.name), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fb08bbd-8ffa-4ccd-8f15-a7c5d0c091ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = VOCAB.groupby('stem_porter').size().reset_index(name='porter_count')\n",
    "snowball = VOCAB.groupby('stem_snowball').size().reset_index(name='snowball_count')\n",
    "lancaster = VOCAB.groupby('stem_lancaster').size().reset_index(name='lancaster_count')\n",
    "\n",
    "# Merge the counts together\n",
    "counts = porter.merge(snowball, left_on='stem_porter', right_on='stem_snowball', how='outer')\\\n",
    "                            .merge(lancaster, left_on='stem_porter', right_on='stem_lancaster', how='outer')\n",
    "counts.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9333096-cfd0-4c39-9d27-902d83fc0596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter: 11.0\n",
      "Snowball: 11.0\n",
      "Lancaster: 34.0\n"
     ]
    }
   ],
   "source": [
    "# Look at max values first:\n",
    "\n",
    "print(f\"Porter: {counts.porter_count.max()}\")\n",
    "print(f\"Snowball: {counts.snowball_count.max()}\")\n",
    "print(f\"Lancaster: {counts.lancaster_count.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56498940-7a69-4810-99da-8fb4c42d59fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter: 1.501539338654504\n",
      "Snowball: 1.5309539033889439\n",
      "Lancaster: 1.8024226663016698\n"
     ]
    }
   ],
   "source": [
    "# Now averages:\n",
    "\n",
    "print(f\"Porter: {counts.loc[counts['porter_count'] > 0, 'porter_count'].mean()}\")\n",
    "print(f\"Snowball: {counts.loc[counts['snowball_count'] > 0, 'snowball_count'].mean()}\")\n",
    "print(f\"Lancaster: {counts.loc[counts['lancaster_count'] > 0, 'lancaster_count'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8c9244-7761-4bca-993b-50a6e13c9f61",
   "metadata": {},
   "source": [
    "The Lancaster stemming algorithm is the most aggressive, as it has the greatest number of words associated with each stem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1876a-28ef-443e-a931-c05540efe6fb",
   "metadata": {},
   "source": [
    "#### 5. Using the most aggressive stemmer from the previous question, what is the stem with the most associated terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "924deb58-d79a-4d10-abf9-1fcbc39399ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cont'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.loc[counts.lancaster_count.idxmax(), 'stem_lancaster']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
